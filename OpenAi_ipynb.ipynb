{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-m64AvF7xD5"
      },
      "source": [
        "# Instalando as bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b2b3cAlKfCxG"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf1KudeQ70hz"
      },
      "outputs": [],
      "source": [
        "!pip install transformers  beautifulsoup4 requests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuzwcsLxOK1T"
      },
      "source": [
        "# Declarando as bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8f25_DrYOJV0"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, BertTokenizerFast, EncoderDecoderModel\n",
        "import torch\n",
        "import openai\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8tDE2VeR5Ie"
      },
      "source": [
        "# Raspando dados da internet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8IzD7ATGR9-G"
      },
      "outputs": [],
      "source": [
        "def extraindo_texto_da_web(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Verifica se o request foi bem-sucedido\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Extrai todo o texto visível da página\n",
        "    paragraphs = soup.find_all('p')\n",
        "    text = \" \".join([para.get_text() for para in paragraphs])\n",
        "    return text\n",
        "\n",
        "url = \"https://pt.wikipedia.org/wiki/Microsoft_Office\"\n",
        "\n",
        "documento = extraindo_texto_da_web(url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NaRYm4G77Pe"
      },
      "source": [
        "# Usando o OPENAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7R30D75ugOFL"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"Use the your API\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFHGoUh0cbIO"
      },
      "source": [
        "## Q & R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2qIN-Pv78wE"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "pergunta = input(\"Make your question: \")\n",
        "\n",
        "prompt = f\"Contexto: {documento}\\nPergunta: {pergunta}\\nResposta:\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Você é um assistente útil.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ],\n",
        "    max_tokens=50,\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "# Exibe a resposta da pergunta\n",
        "resposta = response['choices'][0]['message']['content'].strip()\n",
        "print(f\"Resposta: {resposta}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6ope5hC79nT"
      },
      "source": [
        "## Summarize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ucq1sCKHcfqb"
      },
      "outputs": [],
      "source": [
        "prompt = f\"Resuma o seguinte texto de forma concisa:\\n{documento}\"\n",
        "\n",
        "# Solicitação para o modelo GPT-3.5-turbo para resumir o texto\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Você é um assistente que pode resumir textos.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ],\n",
        "    max_tokens=100,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# Exibe o resumo\n",
        "resumo = response['choices'][0]['message']['content'].strip()\n",
        "print(f\"Resumo: {resumo}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM19BQJccgYs"
      },
      "source": [
        "## Análise de Sentimento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LfyhmkEch-0"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Texto para análise de sentimento\n",
        "texto = \"\"\"\n",
        "Maycon é um cara muito legal, eu amo ele!\n",
        "\"\"\"\n",
        "\n",
        "# Prompt para análise de sentimento\n",
        "prompt = f\"Classifique o sentimento do seguinte texto como 'Positivo', 'Negativo' ou 'Neutro':\\n{texto}\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=\"gpt-3.5-turbo\",  # Ou \"gpt-3.5-turbo\" ou outro modelo de chat compatível\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Você é um assistente útil.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ],\n",
        "    max_tokens=60,\n",
        "    temperature=0.0  # Temperatura baixa para respostas diretas\n",
        ")\n",
        "\n",
        "# Extrair e exibir o sentimento\n",
        "sentimento = response['choices'][0]['message']['content'].strip()\n",
        "print(f\"Sentimento: {sentimento}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "06JuIP-F68qE",
        "H8tDE2VeR5Ie",
        "3rc2DD_j9a_J",
        "KMYS2307U6Dg",
        "6NaRYm4G77Pe"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}